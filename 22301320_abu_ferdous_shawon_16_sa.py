# -*- coding: utf-8 -*-
"""22301320_Abu_Ferdous_Shawon_16-SA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/131p6FnK90L6R3T_671bmP5cS_RGcRffm
"""

NAME = "Abu Ferdous Shawon"
ID = "22301320"
SECTION = "16"

"""# Instructions:

This is your special assessment for CSE330 Lab. ***Please read the instructions carefully!***

1. You must rename this file as "ID_Name_Section_SA.ipynb". Example: "21212121_Niloy Farhan_01-SA.ipynb".
2. There are 4 tasks and each task have several substasks. This tasks are based on the content of lab 5 and lab 6.
3. You must use designated cells for each task. You should not use additional cells for codes of a task.
4. Some task may have no output. It will be mentioned in the designated cells.
5. Not a single line of code of this assessment should be written by AI. If you do, karma will hit you back. ;)
6. **Plagarism can lead to a zero mark in Final Assessment.**
7. If you have any queries, reach out to your lab faculties.


**Best of luck!**

# Task1.


Let $f(x)$ be a function of $x$.

$$f(x) = x^5 + 2.5x^4 - 2x^3 -6x^2 + x + 2\tag{1.1}$$

a. Plot the function for $$-2.5 \le x \le 1.5$$

b. What is the actual slope of $f(x)$ at $x = 0 , -1.18625$ ?  Print $f'(x)$ and plot $f'(x)$ at $ -2 \le x \le 1.2$.

For c to e, assume step size is $0.1$.

c. Use forward differntiation to figure out the slope at $x = 0 , -1.18625$.

d. Use backward differntiation to figure out the slope at $x = 0 , -1.18625$.

e. Use central differntiation to figure out the slope at $x = 0 , -1.18625$.

f. Compare the error of each method with actual differentiation at $x = 0 , -1.18625$ by showing in a Pandas Dataframe.

g. plot error vs h curves with proper label and color for each method at $x = 0$ and $h = [0.55, 0.3, .17, 0.1, 0.055, 0.03, 0.017, 0.01]$.
"""

# Import cells. This is done for you!
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from numpy.polynomial import Polynomial

#1.a This cell should plot a graph. You must use polynomial class.
f = Polynomial([2.0,1.0,-6.0,-2.0,2.5,1.0])
x = np.linspace(-2.5, 1.5, 100)
y = f(x)
plt.plot(x, y)
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid(True)
plt.show()

#1.b This cell should print and plot a graph.
slope = f.deriv()
#x=0
print(f"Slope at x= 0 is {slope(0)}")
#x=-1.18625
print(f"Slope at x= 0 is{slope(-1.18625)}")
print(f"f'(x) is {slope}")
x = np.linspace(-2, 1.2, 100)
y = slope(x)
plt.plot(x, y)
plt.xlabel('x')
plt.ylabel("f'(x)")
plt.grid(True)
plt.show()

#1.c This cell should print
def forward_diff(f, h, x):
  return (f(x+h) - f(x)) / h
h= 0.1
print(forward_diff(f, h, 0))
print(forward_diff(f, h, -1.18625))

#1.d This cell should print
def backward_diff(f, h, x):
  return (f(x)-f(x-h))/h
h= 0.1
print(backward_diff(f, h, 0))
print(backward_diff(f, h, -1.18625))

#1.e This cell should print
def central_diff(f, h, x):
  return (f(x+h)-f(x-h))/(2*h)
h= 0.1
print(central_diff(f, h, 0))
print(central_diff(f, h, -1.18625))

#1.f This cell should show a table
def compare(f, f_prime, h, x):
    Result = {'x' : [], "Actual" : [],"FD": [], "BD" : [], "CD": [], "FD Error" : [], "BD Error": [], "CD Error" : []}     #
    #Write code here
    Result["x"] = [x[0],x[1]]
    Result["Actual"] = [slope(x[0]),slope(x[1])]
    Result["FD"]= [forward_diff(f, h, x[0]),forward_diff(f, h, x[1])]
    Result["BD"]= [backward_diff(f, h, x[0]),backward_diff(f, h, x[1])]
    Result["CD"]= [central_diff(f, h, x[0]),central_diff(f, h, x[1])]
    Result["FD Error"]= [abs(slope(x[0])-forward_diff(f, h, x[0])),abs(slope(x[1])-forward_diff(f, h, x[1]))]
    Result["BD Error"]= [abs(slope(x[0])-backward_diff(f, h, x[0])),abs(slope(x[1])-backward_diff(f, h, x[1]))]
    Result["CD Error"]= [abs(slope(x[0])-central_diff(f, h, x[0])),abs(slope(x[1])-central_diff(f, h, x[1]))]
    df = pd.DataFrame(Result)
    return df.head()


compare(f, slope, h, [0, -1.18625])

#1g This cell should plot a graph.
h=[0.55,0.3,.17,0.1,0.055,0.03,0.017,0.01]
x=0
f_error = []
b_error = []
c_error = []
for i in h:
  f_error.append(abs(slope(x)-forward_diff(f, i, x)))
  b_error.append(abs(slope(x)-backward_diff(f, i, x)))
  c_error.append(abs(slope(x)-central_diff(f, i, x)))
plt.plot(h, f_error, label = 'Forward_Error')
plt.plot(h, b_error, label = 'Backward_Error')
plt.plot(h, c_error, label = 'Central_Error')
plt.xlabel('h')
plt.ylabel('Error')
plt.grid(True)
plt.legend()
plt.show()

"""# Task 2.

a. Propose a better technique for numerical differentiation that provides higher accuracy than the methods you have worked so far. You need to write a function for your proposed technique.

Let, $$f(x) = x^5 + 2.5x^4 - 2x^3 -6x^2 + x + 2\tag{2.1}$$

b. Using your proposed method, what is the slope of $f(x)$  at $x=0,−1.18625$ and step size = 0.1?

c. Compare the error of your method with  actual, forward, backward and central differentiation at  $x=0,−1.18625$  by showing in Pandas Dataframe.

d. Plot actual derivative, Forward derivative, Backward derivative, Central derivative and the derivative from your proposed method in a graph. Here, $$h = 0.1, -2 \le x \le 1.2$$
"""

#2a. This cell should not have any output.
Proposed_Method_Name = "Richardson Extrapolation"

#Write Code here
def dh(f, h, x):
  return (f(x+h)-f(x-h))/(2*h)

def dh1(f, h, x):
  return ((4*dh(f,h/2,x))-dh(f,h,x))/3

#2b. This cell should print
f = Polynomial([2.0, 1.0, -6.0, -2.0, 2.5, 1.0])
h = 0.1
print(dh1(f, h, x=0))
print(dh1(f, h, x=-1.18625))

#2c.This cell should print

def compare1(f, f_prime, h, x):
    Result = {'x' : [], "Actual" : [],"FD": [], "BD" : [], "CD": [],"RE": [], "FD Error" : [], "BD Error": [], "CD Error" : [], "RE Error" : []}
    #Write code here
    Result["x"] = [x[0],x[1]]
    Result["Actual"] = [slope(x[0]),slope(x[1])]
    Result["FD"]= [forward_diff(f, h, x[0]),forward_diff(f, h, x[1])]
    Result["BD"]= [backward_diff(f, h, x[0]),backward_diff(f, h, x[1])]
    Result["CD"]= [central_diff(f, h, x[0]),central_diff(f, h, x[1])]
    Result["RE"]= [dh1(f, h, x[0]),dh1(f, h, x[1])]
    Result["FD Error"]= [abs(slope(x[0])-forward_diff(f, h, x[0])),abs(slope(x[1])-forward_diff(f, h, x[1]))]
    Result["BD Error"]= [abs(slope(x[0])-backward_diff(f, h, x[0])),abs(slope(x[1])-backward_diff(f, h, x[1]))]
    Result["CD Error"]= [abs(slope(x[0])-central_diff(f, h, x[0])),abs(slope(x[1])-central_diff(f, h, x[1]))]
    Result["RE Error"]= [abs(slope(x[0])-dh1(f, h, x[0])),abs(slope(x[1])-dh1(f, h, x[1]))]
    df = pd.DataFrame(Result)
    return df.head()

slope = f.deriv()
compare1(f,slope,h,[0,-1.18625])

#2.d This cell should plot a graph.
x = np.linspace(-2, 1.2, 100)
plt.plot(x, slope(x), label = 'Actual')
plt.plot(x, forward_diff(f, h, x), label = 'Forward')
plt.plot(x, backward_diff(f, h, x), label = 'Backward')
plt.plot(x, central_diff(f, h, x), label = 'Central')
plt.plot(x, dh1(f, h, x), label = 'Richardson Extrapolation')
plt.grid(True)
plt.legend()
plt.show()

"""# Task 3.

Given,
$f(x) = \frac{-1}{13}x^3 + 2x^2 - 9.5x - 10\tag{3.1}$

a. (i) Write a python function that takes an input function and a list of intervals as a list and returns a dictionary that contains either root exists or not in each intervals.
Determine if root exists in $[(-20,-10),(-10,0), (0,10), (10,20), (20,30)]$.

(ii) Verify your method by ploting the function and the intervals.
"""

#3a_i This cell should print
intervals = [(-20,-10),(-10,0), (0,10), (10,20), (20,30)]  #  This snippet will be given in the question
f = Polynomial([-10.0,-9.5,2.0,-1/13])
dic = {}
def roots(f,intervals):
  for i in intervals:
    a,b = i
    z= f(a)*f(b)
    if z<0:
      dic[i] = "Root Exists"
    else:
      dic[i] = "Root Does not Exists"
  return dic
roots(f,intervals)

#3a_ii This cell should plot a graph.
intervals = [(-20,-10),(-10,0), (0,10), (10,20), (20,30)]
f = Polynomial([-10.0,-9.5,2.0,-1/13])
x = np.linspace(-20, 30, 100)
y = f(x)
plt.axhline(y=0, color='r')
plt.plot(x, y)
print(f.roots())
plt.plot(f.roots(),[0]*len(f.roots()),'go')
plt.grid(True)
plt.show()

"""b. Using Bisection method, find roots of the function $3.1$ in these intervals $[(−20,−10),(−10,0),(0,10),(10,20),(20,30)]$ where root exists. The value of machine epsilon is, $\epsilon < 10^{-6}$


You can reuse the function of Task 3.a to find out the intervals that contains root.
Note: You should return 3 different roots for the function (3.1).
"""

#3b This cell should print
f = Polynomial([-10.0,-9.5,2.0,-1/13])
intervals = [(-20,-10),(-10,0), (0,10), (10,20), (20,30)]
roots_interval = roots(f,intervals)
roots_list = []
for k,v in roots_interval.items():
  if v == "Root Exists":
    a = k[0]
    b = k[1]
    mid = (a+b)/2
    e = 1e-6
    root = 0.0
    while True:
      if f(mid) == 0:
        root = mid
        roots_list.append(root)
        print(f"Root of the interval {k} is {root}")
        break
      if f(b)*f(mid)<0:
        a=mid
      else:
        b=mid
      old_mid = mid
      mid = (a+b)/2
      if abs(mid - old_mid)/abs(mid)<e:
        root = mid
        roots_list.append(root)
        print(f"Root of the interval {k} is {root}")
        break

"""c. Plot the f(x) along with the roots to check if your method is working correctly."""

#3c This cell plot a graph.
x = np.linspace(-20,30,100)
y = f(x)
plt.axhline(y=0, color='r')
plt.plot(x, y,'y')
plt.xlabel("Intervals")
plt.ylabel("f(x)")
for i in roots_list:
  plt.plot(i, f(i), 'go')
  print(i)
plt.grid(True)
plt.show()

"""Task4.


Let $f(x)$ be a function of $x$.

$$f(x) = x^5 + 2.5x^4 - 2x^3 -6x^2 + \frac{x}{2} + 2\tag{4.1}$$

a. Find the actual roots of $f(x)$ and print them.

b. Plot the function for $-2.5 \le x \le 1.5$, also point out the the found roots in the plot

c. The following $g_{1}(x)$ is given which is derived from Eq$(4.1)$, \\
   Use Contraction Mapping Theorem and calculate the value of λ for the given $g(x)$ $$g_{1}(x)= \frac{1}{2}(-x^5 - 2.5x^4 + 2x^3 + 6x^2 - 2)\tag{4.2}$$

d. Compute the convergence/divergence table using all the calculated roots for the given $g_{1}(x)$ and prove the whole $g_{1}(x)$ is divergent

Given,

$$g_{2}(x)= \sqrt{\frac{1}{6}(x^5 + 2.5x^4 -2x^3 + \frac{1}{2}x + 2)}\tag{4.3}$$
$$g_{3}(x) = \sqrt[\leftroot{-1}\uproot{2}\scriptstyle 4]{\frac{1}{2.5}(-x^5 + 2x^3 + 6x^2 - \frac{1}{2}x - 2)}\tag{4.4}$$
e. Derive 2 more separate $g_{4}(x)$ and $g_{5}(x)$ from the given $f(x)$. Implement $g_{2}(x)$, $g_{3}(x)$, $g_{4}(x)$ and $g_{5}(x)$.

f. Apply Fixed Point Method on the $g_{2}(x)$, $g_{3}(x)$, $g_{4}(x)$ and $g_{5}(x)$. and find the approprate roots, show 20 iterations for each $g(x)$ for $x_{0}$ = 0.8 and show the convergence table using data from each iteration

g. Plot the $g(x)$s where actual roots were found along with $f(x)$.
"""

#4a This cell should print
f = Polynomial([2.0,0.5,-6.0,-2.0,2.5,1.0])
print(f.roots())

#4b This cell should print plot a graph
x = np.linspace(-2.5,1.5,100)
y = f(x)
plt.axhline(y=0, color = 'r')
plt.plot(x,y)
print(f.roots())
plt.plot(f.roots(),[0]*len(f.roots()),'go')
plt.grid(True)
plt.show()

#4c This cell should print
roots = f.roots()
g = Polynomial([-2.0,0.0,6.0,2.0,-2.5,-1.0])
g1 = g/2
lamb = []
g1_prime = g1.deriv()
for i in roots:
  lamb.append(abs(g1_prime(i)))
print(lamb)

#4d This cell should print
table = {"Roots" : roots, "Lambda" : lamb, "Convergence/Divergence" : []}
for j in lamb:
  if j>=1:
    table["Convergence/Divergence"].append("Divergence")
  if j == 0:
    table["Convergence/Divergence"].append("Super linear Convergence")
  if 0<j<1:
    table["Convergence/Divergence"].append("Linear Convergence")
df = pd.DataFrame(table)
print(df)
print("The whole g1(x) is Divergent. PROVED")

#4e This cell have no outputs
def g4(x):
  p = Polynomial([2.0,0.5,-3.0,-2.0,2.5,1.0])
  return np.sqrt(p(x)/3)

def g5(x):
  p = Polynomial([-2.0,-1/2,6.0,2.0,-2.5,0.0])
  return np.power(p(x), 1.0/5.0)

def g2(x):
  p = Polynomial([2.0,1/2,0.0,-2.0,2.5,1.0])
  return np.power(p(x)/6, 1.0/2.0)

def g3(x):
  p = Polynomial([-2.0,-1/2,6.0,2.0,0.0,-1.0])
  return np.power(p(x)/2.5, 1.0/4.0)

def ad(a,b=[]):
  b.append(a)
  return b

a1=ad(1)
a2=ad(2,[])
print(a1,a2)

#4f This cell should print
x2 = 0.8
g2_x = []
x3 = 0.8
g3_x = []
x4 = 0.8
g4_x = []
x5 = 0.8
g5_x = []
g2_x.append(x2)
g3_x.append(x3)
g4_x.append(x4)
g5_x.append(x5)
for i in range(20):
  x2 = g2(g2_x[i])
  g2_x.append(x2)
  x3 = g3(g3_x[i])
  g3_x.append(x3)
  x4 = g4(g4_x[i])
  g4_x.append(x4)
  x5 = g5(g5_x[i])
  g5_x.append(x5)
print(pd.DataFrame({'g2(x)':g2_x, 'g3(x)':g3_x, 'g4(x)':g4_x, 'g5(x)':g5_x}))

#4g This cell should plot a graph. Do not plot those g(x) which will not converge.
x = np.linspace(-2.5,1.5,100)
y = f(x)
plt.axhline(y=0, color = 'r')
plt.plot(x, f(x), label='f(x)', color='y')
plt.plot(x, g2(x), label='g2(x)', color ='b')
plt.plot(x, g3(x), label='g3(x)', color = 'm' )
plt.plot(x, g4(x), label='g4(x)', color = 'g')
plt.plot(x, g5(x), label='g5(x)', color='r')
plt.grid(True)
plt.legend()
if len(g2_x) > 0:
    root = np.array([g2_x[len(g2_x)-1], g3_x[len(g3_x)-1], g5_x[len(g5_x)-1]])
    plt.plot(root, f(root), 'ko')